{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1: Análisis de sentimiento (Reviews de rotten tomatoes)\n",
    "En este proyecto utilizaremos el Rotten tomatoes dataset  el cual contiene 8530 reseñas de tipo string con hasta 267 caracteres, y 1066 reseñas en validación. Tu trabajo es predecir si la reseña se expresa positiva o negativamente para las que se encuentren en el conjunto de validación de la mejor manera posible, utilizando la experiencia pasada dada en las 8530 reseñas de entrenamiento. Además, analizarás la eficacia de tu modelo y evaluarás si el modelo ha aprendido correctamente.\n",
    "\n",
    "A diferencia de los ejercicios anteriores donde programaste las soluciones analíticas a los métodos de ML, en este proyecto se recomienda el uso de las funciones y clases integradas de scikit-learn. Para entender el uso de estas clases y ver algunos ejemplos puedes consultar la documentación oficial [sk-learn user guide](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "En este proyecto tendrás que elegir que método de reducción de dimensionalidad y que método de agrupamiento deseas aplicar a tus datos. Es tu trabajo analizar la información dada para tomar estas decisiones. Lee con atención todas las instrucciones y celdas de código, y recuerda agregar tu código en todas las partes donde veas la instrucción \"`TODO`\"\n",
    "\n",
    "## Descripción:\n",
    "1. Dado que los datos están en forma de texto, será necesario transformarlos a un vector de números\n",
    "2. Aplicar un método de reducción de dimensionalidad y visualizar los datos\n",
    "3. Buscar grupos en los datos reducidos con alguna técnica de agrupamiento o clasificación.\n",
    "4. Interpretar los resultados.\n",
    "5. Dados los textos de validación, identificar a que grupo o clase pertenece. (Inferencia)\n",
    "\n",
    "## Instrucciones\n",
    "En este proyecto también tienes la alternativa de correr el entrenamiento completando el archivo de training.py y preprocessing.py, sin embargo se espera entreges las mismas gráficas y resultados independientemente de si usas el notebook o los archivos de python tradicionales\n",
    "- Si utilizas el archivo de training.py, en preprocessing.py completa el método get_one_hot_vector\n",
    "- De otra forma, si utilizas solo este archivo, completa el código para preprocesar los datos, entrenar y evaluar el modelo.\n",
    "\n",
    "Nota como existen múltiples soluciones a este problema. La decisión de como resolverlo es tuya (: intenta hacerlo lo mejor posible!\n",
    "Comenzamos por importar las librerías correspondientes.\n",
    "\n",
    "En tu blog no olvides incluir:\n",
    "- Análisis del conjunto de datos en baja dimensionalidad\n",
    "- Evaluación cualitativa y cuantitativa (en validación) de al menos dos modelos/métodos de aprendizaje de máquina\n",
    "    - Reportar métricas de clasificación para cada uno \n",
    "    - Dos ejemplos de falsos poitivos\n",
    "    - Dos ejemplos de falsos negativos\n",
    "    - Dos ejemplos de verdaderos positivos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análisis del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = load_dataset('./rotten_tomatoes_dataset.py')\n",
    "training_set = dataset['train']\n",
    "validation_set = dataset['validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_samples(dataset, n_samples, random=True):\n",
    "    if random:\n",
    "        indices = np.random.randint(0, len(dataset), n_samples)\n",
    "    else:\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "    for i in indices:\n",
    "        idx = i.item()\n",
    "        datapoint = dataset[idx]\n",
    "        text = datapoint['text']\n",
    "        label = datapoint['label']\n",
    "        is_pos = \"positive\" if label else \"negative\"\n",
    "        print(f\"({is_pos}) - Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "print(\"# datos de entrenamiento\", training_set.shape)\n",
    "print(\"# datos de validación\", validation_set.shape)\n",
    "print(\"Muestras de entrenamiento\")\n",
    "print_samples(training_set, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_vector(text, vocabulary):\n",
    "    ''' # TODO\n",
    "        Dado un texto y un vocabulario, devuelve un vector one-hot\n",
    "        donde el valor sea 1 si la palabra esta en el texto y 0 en caso contrario.\n",
    "        Ejemplo:\n",
    "            text = 'hola mundo'\n",
    "            vocabulary = {\n",
    "                'hola': 0,\n",
    "                'mundo': 1,\n",
    "                'UNK': 2\n",
    "            }\n",
    "            one_hot = [1, 1, 0]\n",
    "    '''\n",
    "    # Inicializamos un vector en ceros\n",
    "    embedded = np.zeros(len(vocabulary))\n",
    "    # TODO: Modifica los valores segun la descripción\n",
    "    # Si lo deseas, puedes experimentar para que el vector\n",
    "    # contenga la cantidad de veces que aparece la palabra\n",
    "    # en lugar de solo indiccar si existe o no,\n",
    "\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente método llama al anterior para preprocesar el conjunto de datos completo\n",
    "\n",
    "#todo: Investiga sobre Word2Vec e incluye lo que encuentres al respecto en tu blog. ¿Sería una mejor manera de representar el texto?¿Que sería necesario para poder usarlo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_vocab\n",
    "def preprocess_dataset(dataset, vocabulary):\n",
    "    '''\n",
    "        Datado un dataset (x, y) donde x es un texto y y es la etiqueta,\n",
    "        devuelve una matriz X donde cada fila es un vector one-hot\n",
    "        y un vector y con las etiquetas.\n",
    "        Ejemplo:\n",
    "            vocab = {\"hola\": 0, \"mundo\": 1, \"cruel\": 2}\n",
    "            input: \n",
    "            dataset = [\n",
    "                       {\"text\": \"hola mundo cruel\", \"label\": 0},\n",
    "                       {\"text\": \"hola mundo\", \"label\": 1}\n",
    "                       ]\n",
    "            output:\n",
    "            X = [[1, 1, 1],\n",
    "                 [1, 1, 0]]\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        X.append(get_one_hot_vector(sample['text'], vocabulary))\n",
    "        y.append(sample['label'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Tanto en entrenamiento como validación, obtenemos el vocabulario del conjunto de entrenamiento\n",
    "data_train, target_train = preprocess_dataset(training_set, get_vocab(training_set))\n",
    "data_val, target_val = preprocess_dataset(validation_set, get_vocab(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de transformar el texto a modo vector usando la representación anterior, la dimensionalidad de nuestros datos habra cambiado bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datos de entrenamiento\", data_train.shape, target_train.shape)\n",
    "print(\"Datos de validación\", data_val.shape, target_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización en baja dimensionalidad\n",
    "En la siguiente celda puedes visualizar como se ven tus datos reduciendo la dimensionalidad a 2. Explora usar TSNE y PCA, y elige el que te de mejor información. En este caso debido a que la dimensionalidad es demasiado alta, puedes intentar reducir la dimensionalidad en 2 etapas. Por ejemplo, usando pca para reducir los datos inicialmente a 100-300 variables, y consecuentemente usar PCA o TSNE para reducir a 2 o 3 dimensionsiones para visualizacion\n",
    "\n",
    "Utiliza las siguientes preguntas para analizar la imgen:\n",
    "- ¿Cual método de reducción de dimensionalidad funciona mejor en este caso?\n",
    "- ¿Que puedes deducir de esta imagen?\n",
    "- ¿Que ocurre si intentas reducir la dimensionalidad original a 2d en una sola etapa?\n",
    "- ¿Cuál método de redicción es mas eficiente?\n",
    "- ¿Qué representa cada color en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# TODO Reducimos la dimensionalidad de los datos de validacion data_val\n",
    "# a 2 dimensiones usando TSNE y/o PCA\n",
    "reduced_data = \n",
    "\n",
    "labels = np.unique(target_train)\n",
    "fig, ax_pca = plt.subplots(1, 1, figsize=(4,4))\n",
    "fig.suptitle(\"Puntos reducidos a dos dimensiones\")\n",
    "for c in labels:\n",
    "    indices = np.where(target_train == c)\n",
    "    plot_data = reduced_data[indices]\n",
    "    ax_pca.scatter(plot_data[:, 0], plot_data[:, 1], label=f\"Grupo {c}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tu turno! - Entrenamiento\n",
    "Utiliza los datos `data_train` con las etiquetas `target_train` define para entrenar un modelo que identifique dígitos. \n",
    "Utiliza las librerías de sklearn para entrenar al menos dos modelos. En esta sección queda a tu criterio:\n",
    "- Decidir si entrenarás en alta o baja dimensionalidad\n",
    "- Decidir los modelos que deseas comparar\n",
    "- Decidir si quieres usar un método de aprendizaje supervisado o no supervisado, o comparar ambos.\n",
    "- tip: Investiga si existen métdos de aprendizaje de máquina tradicionales que se apliquen principalmente a texto.\n",
    "\n",
    "Puedes consultar todos los modelos disponibles de sklear en el [user-guide](https://scikit-learn.org/stable/supervised_learning.html). \n",
    "\n",
    "En este proyecto puedes jugar con el preprocesamiento de datos, especificamente en la forma en que eliges representar el vector de texto. ¿quieres considerar si una palabra aparece en el vocabulario o cuantas veces lo hace? ¿Quieres excluir algunas palabras del vocabulario? etc. Considera que si la forma en que decidas hacerlo, deberás aplicar a los datos de validación durante inferencia **DE LA MISMA MANERA** en que preprocesaste los datos de entrenamiento. Modifica el método de `preprocess_dataset` y corre el notebook de nuevo para probar distintos experimentos.\n",
    "\n",
    "Considera que **en todo momento** los datos de validación no se usan para encontrar ningún parámetro. Tienes que asumir que no existen hasta el momento que quieras predecir datos usando los modelos que hayas estimado con los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train(X, label, model_type:str):\n",
    "    data = X\n",
    "\n",
    "    # TODO: Entrena el modelo y regresa el modelo entrenado en los datos de entrenamiento\n",
    "    # model puede ser tanto la instancia de la clase que quieras usar, como un string indicando\n",
    "\n",
    "    return estimator\n",
    "\n",
    "def inference(modelo, X_val):\n",
    "    # En inferencia, podemos recibir un solo dato entonces X_val.shape seria (D, )\n",
    "    # Las clases de sklearn siempre esperan todo en la forma de  N, D\n",
    "    if X_val.ndim == 1:\n",
    "        X_val = X_val.reshape(1, -1)\n",
    "    # Normalizamos los datos de validación\n",
    "    # El mismos preprocesamiento de datos se aplica a\n",
    "    # tanto inferencia como entrenamiento\n",
    "    data = X_val\n",
    "\n",
    "    # TODO: Utiliza el modelo para predecir valores para los datos de validación\n",
    "    # Regresa las predicciones de tu modelo para X_val\n",
    "    # En este caso, modelo tiene que ser una instancia de una clase para la cual quieres hacer predicción\n",
    "\n",
    "    return preds\n",
    "\n",
    "trained_models = {\n",
    "    \"algun_modelo\": None,\n",
    "    \"otra_cosa\": None,\n",
    "    ...\n",
    "}\n",
    "for model_type in trained_models.keys():\n",
    "    modelo = train(data_train, target_train, model_type=model_type)\n",
    "    trained_models[model_type] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluación y análisis de las predicciones\n",
    "En esta sección incluimos funciones que te permiten visualizar la predicción de tu modelo para el set de validación. Dado que nuestros datos son de alta dimensionalidad (64) necesitamos reducirlos para poder analizar las predicciones. Recuerda que en esta sección solo funcionará si has definido tu modelo correctamente en el método anterior `mi_modelo`.\n",
    "\n",
    "## 3.1 (Inferencia) Datos de validación en baja dimensionalidad\n",
    "Completa el código de la siguiente celda para visualizar **las predicciones de TU modelo** de el conjunto de validación en baja dimensionalidad. Utiliza el método de reducción de dimensionalidad que consideres te ayude mejor a analizar tus datos. Cada clase/grupo deberá mostrarse en un color diferente. En base a lo que puedes observar en la imagen, ¿consideras que tu algoritmo ha aprendido algo que tiene sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_low_dim(data_val, preds, model_type):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "    fig.suptitle(f\"Puntos clasificados {model_type} (2 dimensiones)\")\n",
    "    n_groups = 2\n",
    "    # Graficamos los datos, con un color diferente para cada clase/grupo\n",
    "    print(f\"Datos {data_val.shape}, predicciones {preds.shape}, clases/grupos {n_groups}\")\n",
    "\n",
    "    # TODO: Reduce los datos de VALIDACIÓN data_val a dos dimensiones para poder visualizarlos\n",
    "    reduced_data = ...\n",
    "    for g in range(n_groups):\n",
    "        # TODO: Grafica los datos de VALIDACIÓN reducidos (reduced_data.shape = (N, 2))\n",
    "        # Tal que grafiques aquellos que correspondan al grupo/clase group\n",
    "        # Investiga plt.scatter, np.where o cómo filtrar arreglos dada una condición booleana\n",
    "        ...\n",
    "    fig.show()\n",
    "    fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 (Inferencia) Análisis cualitativo\n",
    "Completa el código de la siguiente celda. El siguiente código llama al método de inferencia anteriormente definido. Para cada modelo encuentra e imprime:\n",
    "- 2 ejemplos de reseñas falsas positivas\n",
    "- 2 ejemplos de reseñas falsas negativas\n",
    "- 2 ejemplos de reseñas verdaderas positivas\n",
    "- 2 ejemplos de reseñas verdaderas negativas\n",
    "\n",
    "#### Métodos de clasificación\n",
    "Si utilizaste un método de clasificación multiclase, los esperable sería que el valor real de la muestra (GT) sea igual al valor de la predicción para al menos la mayoría de los casos.\n",
    "\n",
    "#### Métodos de agrupamiento\n",
    "Si utilizaste un algoritmo de agrupamiento, es esperable que el valor real de la muestra (GT) no sea igual al grupo de tu predicción. Recuerda que al ser aprendizaje no supervisado, necesitamos adicionalmente \"mapear\" los grupos que haya encontrado el algoritmo a los reales. Puedes usar esta sección para hacer dicho mapeo. Lo mas sencillo es usar un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val, target_val = preprocess_dataset(validation_set, get_vocab(training_set))\n",
    "for name, trained_model in trained_models.items():\n",
    "    # TODO: Para cada modelo, imprime los primeros 2 falsos positivos, 2 falsos negativos, 2 verdaderos positivos y 2 verdaderos negativos\n",
    "    # Revisa el método de 'print_samples' para entender cómo imprimir los textos\n",
    "    # Tip: Investiga el uso y funcionamiento de np.where\n",
    "    preds = inference(modelo, data_val)\n",
    "    fp_idcs = np.where(...)[0]\n",
    "    fn_idcs = ...\n",
    "    vp_idcs = ...\n",
    "    vn_idcs = ...\n",
    "    for idcs in [fp_idcs, fn_idcs, vp_idcs, vn_idcs]:\n",
    "        samples = [validation_set[int(i)]['text'] for i in idcs]\n",
    "        split_labels = ...\n",
    "        split_preds = ...\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 (Inferencia) Análisis cuantitativo: Comparar rendimento de distintos modelos\n",
    "En esta sección evalúa tus dos modelos entrenados en el conjunto de validación utilizando alguna métrica vista en clase (accuracy, F1, Precision, Recall etc.) y determina cuantitativamente cual funciona mejor. Investiga como usar las métricas de sklearn en la sección de [Classification metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# TODO: Para todos los modelos que entrenaste, calcula un valor \n",
    "# que indique la calidad de las predicciones en los datos de validación\n",
    "# utiliza: data_val y target_val\n",
    "for name, trained_model in trained_models.items():\n",
    "    # Calcula la predicción y evalúa la calidad de predicción vs. las etiquetas reales (target_val)\n",
    "    print(f\"Modelo {name}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al análisis tanto cualitativo como cuantitativo, discute en tu blog cual modelo funciona mejor justificando tu razonamiento. Puedes usar las siguientes preguntas como guía según las decisiones que hayas tomado:\n",
    "- ¿Funcionó mejor entrenar en alta o baja dimensionalidad?\n",
    "- ¿Funcionó mejor usar un método de aprendizaje supervisado o no supervisado?\n",
    "- ¿Probaste algún método de preprocesamiento distinto?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
