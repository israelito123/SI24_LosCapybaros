{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "En este ejercicio implementarás la solución analítica de regresión lineal. Además, investigarás la influencia de los puntos extremos en el modelo. Antes de empezar importaremos las librerias necesarias. Después, leeremos el archivo que contiene los datos de entrenamiento.\n",
    "\n",
    "**(TODO) Describe la diferencia entre regresión y clasificación en una oración**\n",
    "\n",
    "## Ejercicio:\n",
    "En la siguiente parte queremos implementar la solución de mínimos cuadrados para regresión lineal. Esto significa que dado un set de puntos $\\{\\mathbf{x_i},y_i\\}$, $i = 1, 2, ..., M$ queremos encontrar la línea (o hiperplano en múltiples dimensiones) que minimice el error cuadrático. Este tipo de error, mide la distancia entre los puntos predichos por el modelo lineal contra los valores reales.\n",
    "\n",
    "La fórmula general de regresión lineal es $\\mathbf{y} = \\mathbf X \\boldsymbol w+ \\mathbf{\\epsilon}$ donde:\n",
    "\n",
    "- $\\epsilon$ es un vector de dimensionalidad $\\mathbb{R}^M$ conteniendo los términos de error $N(0,\\sigma^2)$\n",
    "- $\\mathbf{y}$ es el vector de etiquedas\n",
    "- $\\mathbf{X}$ es la *matriz* de data points de dimensionalidad $\\mathbb{R}^{M \\times D}$. \n",
    "\n",
    "Nos interesa calcular los pesos $\\hat{\\boldsymbol w}$ que definan la función lineal óptima. Como vimos en clase, estos estimados están dados por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\boldsymbol w} = (\\mathbf{X}^{\\rm T}\\mathbf{X})^{-1} \\mathbf{X}^{\\rm T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "**Tu trabajo**\n",
    "1. En el primer ejercicio, generaremos un ruido gausiano de dos dimensiones alrededor de una función lineal. Observa como se general los datos y cuáles son los parámetros reales de $\\boldsymbol{w}$.\n",
    "2. Implementarás la solución analítica de regresión lineal. Para ello debes realizar los siguientes pasos.\n",
    "    1. Modifica la matriz de datos para que se encuentre en la forma de notación aumentada.\n",
    "    2. Calcula los pesos estimados según la fórmula vista en clase, usando las funciones de numpy y python.\n",
    "    3. Visualiza la línea resultante (el modelo) en la misma gráfica que de los datos originales.\n",
    "    3. Calcula la suma de errores residuales de los data points y estima un promedio i.e. $\\sum_{i=1}^M \\|y(x_i) - y_i \\|^2$.\n",
    "    5. Compara tus resultados con la función integrada de numpy `np.linalg.lstsq(...)`\n",
    "3. Finalmente, repite los pasos anteriores para generar un modelo de regresión lineal que resuelva del problema de las casas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \"Toy problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 1)\n",
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Generamos datos aleatorios con una desviación estandar conocida\n",
    "## Alrededor de una funcion lineal conocida y = 1.2x + 5\n",
    "n_muestras = 100\n",
    "ruido_blanco_std = 2\n",
    "X = np.random.randn(n_muestras, 1)\n",
    "eps = np.random.randn(n_muestras, 1) * ruido_blanco_std\n",
    "w = np.array([[5, 1.2]]).T\n",
    "y = w[0] + X * w[1] + eps\n",
    "\n",
    "## Imprimimos la dimensionalidad de nuestros datos de entrada y las etiquetas\n",
    "print(X.shape)  # X es de n_muestras, 1 (variable)\n",
    "print(y.shape)\n",
    "print(w.shape)\n",
    "\n",
    "## Graficar los datos\n",
    "plt.scatter(X, y)\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solución a regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. TODO: Transforma los datapoints X a notación aumentada\n",
    "# Tips: \n",
    "#   - Imprime la forma/dimensionalidad de la matriz con print(X.shape) y verifica que sea del tamaño adecuado\n",
    "#   - Investiga la función de numpy np.concatenate y np.ones\n",
    "n = X.shape[0]\n",
    "ones = np.ones((n, 1))\n",
    "print(ones.shape)\n",
    "print(X.shape)\n",
    "\n",
    "X_augmented = ...\n",
    "print(X_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 TODO: usa la ecuación anterior (X'X)^(-1)X'Y para calcular los pesos\n",
    "# Consejo: \n",
    "#       Utiliza np.dot() o @ para calcular la multiplicación de matrices\n",
    "#       np.linalg.inv() se usa para calcular la matriz inversa\n",
    "#       X.T es la transpuesta de X\n",
    "\n",
    "w_hat = ...\n",
    "print(w_hat.shape)\n",
    "print(w_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 TODO: Calcula las predicciones de tu modelo\n",
    "y_hat = ...\n",
    "print(y_hat.shape)\n",
    "\n",
    "plt.plot(X, y, 'o', label='Datos originales', markersize=10)\n",
    "\n",
    "# TODO: Grafica las predicciones/ la linea resultante\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 TODO: Calcula la suma de errores cuadrádos\n",
    "residual_mio = ...\n",
    "\n",
    "c, m = np.linalg.lstsq(X_augmented, y)[0]\n",
    "y_hat2 = m*X + c\n",
    "\n",
    "## 2.5 TODO: Compara los resultados con la función integrada de numpy 'np.linalg.lstsq'\n",
    "residual_numpy = ...\n",
    "\n",
    "# Graficando\n",
    "plt.plot(X, y, 'o', label='Datos originales', markersize=10)\n",
    "\n",
    "# TODO: Grafica la linea resultante de TU modelo como en la sección anterior\n",
    "\n",
    "# TODO: Grafica la linea resultante de numpy como en la sección anterior\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Imprime y compara la suma de errores cuadrádos calculado por TU metodo y el de numpy\n",
    "print(\"Residuales mios: \", residual_mio)\n",
    "print(\"Residuales numpy:\", residual_numpy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. El efecto de las anomalías\n",
    "\n",
    "En esta sección analizaremos los datos del problema de las casas para buscar una solución a través de regresión lineal.\n",
    "\n",
    "Para ello observaremos los datos y aplicaremos un modelo de regresión lineal a los mismos. Después realizarás los mismo pasos en un conjunto con datos filtrados a fin de encontrar un mejor modelo.\n",
    "\n",
    "Tu trabajo:\n",
    "1. Utiliza la librería de scikit-learn para encontrar la solución de regresión lineal para el problema de las casas usando el **conjunto de datos de entrenamiento (train_data)**\n",
    "2. Calcula el error cuadrático en el **conjunto de validación (val_data)**.\n",
    "3. Repite los dos pasos anteriores para los datos filtrados y observa la diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jessi\\Documents\\git repos\\Sistemas inteligentes 2024\\SI24\\src\\si24\\datasets\\house_prices\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def read_data(data_dir, file):\n",
    "    path = os.path.abspath(os.path.join(data_dir, file))\n",
    "    print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "# Leer los datasets\n",
    "data_dir = \"../../datasets/house_prices\"\n",
    "data = read_data(data_dir, \"train.csv\")\n",
    "\n",
    "# Filtrar los datos para seleccionar las columnas de interes\n",
    "# y dejar solo los datos del 2010\n",
    "selected_dim = [\"LotArea\", \"SalePrice\"]\n",
    "data = data[data[\"YrSold\"] <= 2009]\n",
    "data = data[selected_dim]\n",
    "\n",
    "# Separamos los datos en diferentes conjuntos\n",
    "n_datapoints = len(data)\n",
    "train_data = data[:-n_datapoints//4]\n",
    "val_data = data[-n_datapoints//4:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización\n",
    "En la siguiente celda visualizamos los datos originales. Observa como contine una distribución densa para cases con un area menor a 50k sqft y un precio menor a 600k USD, y por otro lado contiene datos escasos fuera de estos rangos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_data(x, labels):\n",
    "    x_label = \"Área (sqft)\"\n",
    "    y_label = \"Precio (USD)\"\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.scatter(x, labels, edgecolors='black') # x, y\n",
    "    ax.set_ylabel(y_label, fontweight='bold')\n",
    "    ax.set_xlabel(x_label, fontweight='bold')\n",
    "    ax.grid(linestyle='--')\n",
    "    return fig, ax\n",
    "\n",
    "# Definir variables y etiquetas\n",
    "X = np.array(train_data[\"LotArea\"])\n",
    "y = np.array(train_data[\"SalePrice\"])\n",
    "\n",
    "# Visualizar los datos originales\n",
    "fig, ax = plot_data(X, y)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión en datos originales\n",
    "\n",
    "Primero aplicaremos regresión lineal a los datos íntegros para observar el efecto de conservar los datos extremos en el entrenamiento del modelo.\n",
    "\n",
    "Puedes consultar la documentación de sci-kit learn para  [regresión lineal](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) en línea para obtener detalles de como utilizar la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# TODO: Usas la funcion integrada de scikit learn para encontrar un modelo de regresión lineal que se ajuste a los datos de entrenamiento y obtén las predicciones\n",
    "modelo = LinearRegression()\n",
    "preds = ...\n",
    "\n",
    "# Graficamos los datos originales\n",
    "fig, ax = plot_data(X, y)\n",
    "# TODO: Grafica la linea resultante sobre los datos originales\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# TODO: calcula el error cuadrado promedio\n",
    "mean_error = ...\n",
    "print(mean_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de datos\n",
    "Como observamos, estos datos presentan múltiples valores aislados lo que afecta la solución de regresión lineal. \n",
    "\n",
    "En la siguiente sección, remueve los valores aislados y repite los pasos anteriores para encontrar un modelo de regresión lineal. C\n",
    "\n",
    "Calcula el error cuadrático los datos filtrados. \n",
    "\n",
    "(TODO: Responde) ¿Cuál es el efecto de pre procesar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remueve los outliers seleccionando un valor que consideres apropiado (filtra los valores de LotArea y  SalePrice=) hasta que los datos se encuentren densamente concentrados en una región\n",
    "train_data_filtrada = train_data[train_data[\"LotArea\"] <= ???]\n",
    "train_data_filtrada = train_data_filtrada[train_data[\"SalePrice\"] <= ???]\n",
    "\n",
    "# Definir variables y etiquetas\n",
    "X_filtered = np.array(train_data_filtrada[\"LotArea\"])\n",
    "y_filtered = np.array(train_data_filtrada[\"SalePrice\"])\n",
    "\n",
    "# Graficar de nuevo\n",
    "fig, ax = plot_data(X_filtered, y_filtered)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión en datos filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X_filtered.reshape(-1, 1)\n",
    "\n",
    "# TODO: Utiliza la clase de LinearRegression de la librería de sci-kit learn para encontrar el modelo de regresión lineal para los datos.\n",
    "\n",
    "\n",
    "# TODO: Grafica la linea resultante sobre los datos originales (train_data)\n",
    "\n",
    "\n",
    "# TODO: calcula el error cuadrado promedio\n",
    "mean_error_new = ...\n",
    "\n",
    "# Visualiza como cambia el error cuando filtramos los datos\n",
    "print(mean_error_new)\n",
    "print(\"diferencia de error\", mean_error - mean_error_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Responde las siguientes preguntas\n",
    "\n",
    "**¿Qué puedes concluir de este ejemplo?**\n",
    "\n",
    "**¿Cuál de las dos soluciones es un mejor modelo de nuestros datos?**\n",
    "\n",
    "**¿Además de filtrar los datos, qué estrategias puedes tomar para penalizar más levemente a los valores aislados?**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
